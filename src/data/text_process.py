import re


def clean(tweets_df, text_col='text'): #, min_nr_words=4, min_nr_cjk=4,
                # cld=DEFAULT_CLD, acc_th=0.9, langs_agg_dict=None):
    '''
    From a DataFrame of tweets, detects the language of the text contained in
    'text_col' and output the result in new columns. Before calling a langauge
    detector, the text is pre-processed to rid it of hashtags, usernames in
    mentions and urls. Also, after these are removed, if the remaining text
    is strictly less than 'min_nr_words' words long, we don't bother calling the
    language detector, which will be unreliable anyway.
    '''
    tweets_lang_df = tweets_df.copy()
    # Match anything starting with @ or # followed by one or more word
    # characters, and which is between word boundaries or at the start or end of
    # the string.
    hash_at_pattern = r'(?:^|\B)((@|#)\w+)(?:$|\b)'
    # Match anything containing /t.co/ surrounded by non-whitespace characters
    # and which is between whitespaces or at the start or end of the string. May
    # be better with all http options at the start, here's it's pretty loose.
    url_pattern = r'(?:^|\s)(\S+\/t.co\/\S+)(?:$|\b)'
    regex_filter = re.compile('({})|({})'.format(hash_at_pattern, url_pattern))
    tweets_lang_df['filtered_text'] = tweets_lang_df[text_col].str.replace(
        regex_filter, '')
    foursquare_mask = tweets_lang_df['source'].str.contains('foursquare')
    im_at_mask = tweets_lang_df['text'].str.startswith("I'm at ")
    # These tweets are generated by Foursquare based on people's location, so
    # they don't tell us anything about the user's language.
    tweets_lang_df.loc[foursquare_mask & im_at_mask, 'filtered_text'] = ''
    # Tweets generated by Foursquare can also end with '(@ <location>)', so we
    # get rid of this part which is useless for language detection, as proper
    # nouns just confuse the detector.
    tweets_lang_df.loc[foursquare_mask, 'filtered_text'] = (
        tweets_lang_df.loc[foursquare_mask, 'filtered_text']
                      .str.replace(r'\(@ .*$', '')
    )
    # Tweets generated by Instagram can end with ' @ <location>', so we
    # get rid of this part which is useless for language detection, as proper
    # nouns just confuse the detector.
    insta_mask = tweets_lang_df['source'].str.contains('instagram')
    tweets_lang_df.loc[insta_mask, 'filtered_text'] = (
        tweets_lang_df.loc[insta_mask, 'filtered_text']
                      .str.replace(r' @ .*$', '')
    )
    # Tweets generated by Path can contain information about the location
    # (after a 'at') and/or the people the user was with (after a 'with'). This
    # metadata is either in parentheses after the core of the tweet, or, if
    # there's is no core text, right at the start without parentheses. Thus we
    # extract only the core text from what's before a '(at' or '(with'.
    path_mask = tweets_lang_df['source'].str.contains('path')
    tweets_lang_df.loc[path_mask, 'filtered_text'] = (
        tweets_lang_df.loc[path_mask, 'filtered_text']
                      .str.extract(r'(.*)(?:\(with|\(at)', expand=False)
    )
    # Extract returns NaN if there's no match, so we need to convert these
    # to the empty string to avoid errors.
    tweets_lang_df.loc[tweets_lang_df['filtered_text'].isnull(),
                       'filtered_text'] = ''
    return tweets_lang_df
    